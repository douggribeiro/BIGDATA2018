{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atributo': 'CAMPANHA', 'nodes': {'fbz_mov_marvel_f3': {'atributo': 'ACEITE', 'nodes': {'alto': {'atributo': 'EXCELENTE'}, 'normal': {'atributo': 'BOM'}}}, 'fbz_mov_ubook_f5': {'atributo': 'BOM'}, 'fbz_ups_bonif_gamedom_f4': {'atributo': 'SEMANA', 'nodes': {'wed': {'atributo': 'RUIM'}, 'thu': {'atributo': 'BOM'}, 'mon': {'atributo': 'BOM'}, 'fri': {'atributo': 'RUIM'}, 'tue': {'atributo': 'BOM'}, 'sat': {'atributo': 'BOM'}}}, 'fbz_zed_clubfun_f15': {'atributo': 'BOM'}, 'fbz_gld_bonif_suarenda_f2': {'atributo': 'BOM'}, 'fbz_noa_joogos_f3': {'atributo': 'EXCELENTE'}, 'fbz_zed_bonif_revista_f25': {'atributo': 'ACEITE', 'nodes': {'alto': {'atributo': 'EXCELENTE'}, 'normal': {'atributo': 'RUIM'}}}, 'fbz_mov_starwars_f4': {'atributo': 'ACEITE', 'nodes': {'alto': {'atributo': 'EXCELENTE'}, 'normal': {'atributo': 'BOM'}}}, 'fbz_zed_recompensa_f16': {'atributo': 'BOM'}, 'fbz_zed_sonhopremio_f1': {'atributo': 'ACEITE', 'nodes': {'alto': {'atributo': 'EXCELENTE'}, 'normal': {'atributo': 'BOM'}}}, 'fbz_mov_bonif_marvel_f4': {'atributo': 'ACEITE', 'nodes': {'alto': {'atributo': 'BOM'}, 'normal': {'atributo': 'RUIM'}}}, 'fbz_mov_playkids_f14': {'atributo': 'ALCANCE', 'nodes': {'alto': {'atributo': 'EXCELENTE'}, 'normal': {'atributo': 'BOM'}, 'baixo': {'atributo': 'EXCELENTE'}}}, 'fbz_ups_saudeup_t1': {'atributo': 'EXCELENTE'}, 'fbz_twe_appgame_f1': {'atributo': 'BOM'}, 'fbz_zed_revista_f13': {'atributo': 'BOM'}}}\n"
     ]
    }
   ],
   "source": [
    "# Douglas Galetti Ribeiro  - BigData 2018\n",
    "#\n",
    "\n",
    "import os.path\n",
    "import math\n",
    "\n",
    "\n",
    "### Funcoes pre processamento da base de dados\n",
    "def preProcessamento():\n",
    "\n",
    "    listaPronta = processaDados('/home/rockman/BIGDATA2018/Spark_project', 'abc.txt')\n",
    "    \n",
    "    # adiciona atributos (cabecalho) ao arquivo processado\n",
    "    dados = []\n",
    "    atributosAmostra = ['CAMPANHA', 'SEMANA', 'ALCANCE', 'ACEITE', 'PERFORMANCE']\n",
    "    dados.append(atributosAmostra)\n",
    "\n",
    "    for valores in listaPronta:\n",
    "        dados.append(valores)\n",
    "    return dados, atributosAmostra\n",
    "\n",
    "\n",
    "# pre-processamento dos dados para formato legivel ao ID3\n",
    "def processaDados (path, nomeArquivo):\n",
    "\n",
    "    arquivo = os.path.join(path, nomeArquivo ) \n",
    "\n",
    "    # cria RDD, mapeia arquivo e obtem apenas os valores de interesse\n",
    "    valores = (sc.textFile(arquivo)).map(lambda x: x.split(',')).map(lambda x: (x[0], int(x[1]), int(x[2]), int(x[3])))\n",
    "\n",
    "    # reduce da campanha com a soma dos totais\n",
    "    totais = valores.map(lambda x: (x[0],x[1])).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "    # reduce da campanha com a soma dos deliveries\n",
    "    deliv = valores.map(lambda x: (x[0],x[2])).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "    # reduce da campanha com a soma dos acceptances\n",
    "    accept = valores.map(lambda x: (x[0],x[3])).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "    # junta valores segundo o grupo (campanha)\n",
    "    joinValores = totais.join(deliv).join(accept).map(lambda x: (x[0],x[1][0][0],x[1][0][1],x[1][1]))\n",
    "\n",
    "    # calcula percentagem delivery/total e acceptance/delivery\n",
    "    calculaPerc = joinValores.map(lambda x: (x[0],int(x[2]/x[1]*100) ,int(x[3]/x[2]*100)))\n",
    "\n",
    "    # classifica percentual delivery\n",
    "    deliveryPerc = calculaPerc.map(lambda x: (x[0],x[1] < 50 and 'baixo' \n",
    "                                         or (x[1] >=50 and x[1] <70 and 'normal') \n",
    "                                         or (x[1] >= 70 and 'alto'),x[2]))\n",
    "\n",
    "    # classifica percentual acceptance\n",
    "    acceptPerc = deliveryPerc.map(lambda x: (x[0],x[1],x[2] < 2 and 'baixo' \n",
    "                                           or (x[2] >=2 and x[2] <3 and 'normal') \n",
    "                                           or (x[2] >= 3 and 'alto')))\n",
    "\n",
    "    # classifica campanha com base nas classificacoes de delivery e acceptance\n",
    "    classifica = acceptPerc.map(lambda x: (x[0], x[1],x[2], \n",
    "                             (x[1] == 'baixo' and x[2] == 'baixo' and 'PESSIMO') \n",
    "                                      or (x[1] == 'baixo' and x[2] == 'normal' and 'RUIM' )\n",
    "                                      or (x[1] == 'baixo' and x[2] == 'alto' and 'BOM')\n",
    "                                      or (x[1] == 'normal' and x[2] == 'baixo' and 'RUIM')\n",
    "                                      or (x[1] == 'normal' and x[2] == 'normal' and 'BOM')\n",
    "                                      or (x[1] == 'normal' and x[2] == 'alto' and 'BOM')\n",
    "                                      or (x[1] == 'alto' and x[2] == 'baixo' and 'PESSIMO')\n",
    "                                      or (x[1] == 'alto' and x[2] == 'normal' and 'BOM')\n",
    "                                      or (x[1] == 'alto' and x[2] == 'alto' and 'EXCELENTE') \n",
    "                                     ))\n",
    "    listaPronta = classifica.map(lambda x: [x[0].split(';'),x[1],x[2],x[3]]).map(lambda x: [x[0][0],x[0][1],x[1],x[2],x[3]]).collect()\n",
    "    return listaPronta\n",
    "\n",
    "\n",
    "\n",
    "### Funcoes Classificador ID3\n",
    "def mapCabecalho(cabecalhoData):\n",
    "    \n",
    "    # equivalente ao Map, gera atributos e valores. Retorna nome e index\n",
    "    nomeIndex = {}\n",
    "    indexNome = {}\n",
    "    for i in range(0, len(cabecalhoData)):\n",
    "        nomeIndex[cabecalhoData[i]] = i\n",
    "        indexNome[i] = cabecalhoData[i]\n",
    "    return indexNome, nomeIndex\n",
    "\n",
    "\n",
    "def obterColunasAmostra(amostra, atributosAmostra):\n",
    "    \n",
    "    # mapeia colunas da amostra (incluindo o cabecalho) e considera apenas as colunas desejadas\n",
    "    dadosCabecalho = list(amostra['cabecalho'])\n",
    "    dadosLinha = list(amostra['linhas'])\n",
    "    mapeiaColunas = list(range(0, len(dadosCabecalho)))\n",
    "    colunasObtidas = [amostra['nomeIndex'][nome] for nome in atributosAmostra]\n",
    "    colunasRemovidas = [indexCol for indexCol in mapeiaColunas if indexCol not in colunasObtidas]\n",
    "\n",
    "    # deleta todas as colunas que nao fazem parte da amostra\n",
    "    for deletaColuna in sorted(colunasRemovidas, reverse=True):\n",
    "        del dadosCabecalho[deletaColuna]\n",
    "        for l in dadosLinha:\n",
    "            del l[deletaColuna]\n",
    "\n",
    "    # retorna amostra mapeada apenas com as colunas desejadas\n",
    "    indexNome, nomeIndex = mapCabecalho(dadosCabecalho)\n",
    "    return {'cabecalho': dadosCabecalho, 'linhas': dadosLinha,'nomeIndex': nomeIndex, 'indexNome': indexNome}\n",
    "\n",
    "\n",
    "\n",
    "def valoresUnicos(dados):\n",
    "    \n",
    "    # Garante que a amostra tenha apenas valores unicos (importante para calculo da entropia)\n",
    "    indexNome = dados['indexNome']\n",
    "    indexadores = indexNome.keys()\n",
    "    \n",
    "    # mapeia chaves e atributos da amostra\n",
    "    mapeiaValor = {}\n",
    "    for index in iter(indexadores):\n",
    "        mapeiaValor[indexNome[index]] = set()\n",
    "\n",
    "    # gera nova amostra com atributos unicos\n",
    "    for dadosLinha in dados['linhas']:\n",
    "        for index in indexNome.keys():\n",
    "            nomeAtributo = indexNome[index]\n",
    "            val = dadosLinha[index]\n",
    "            if val not in mapeiaValor.keys():\n",
    "                mapeiaValor[nomeAtributo].add(val)\n",
    "    return mapeiaValor\n",
    "\n",
    "\n",
    "\n",
    "def obtemDecisao(dados, atributo):\n",
    "    \n",
    "    # recebe amostra de dados e o atributo correspondente\n",
    "    linhas = dados['linhas']\n",
    "    indexColunas = dados['nomeIndex'][atributo]    \n",
    "    atributos = {}\n",
    "    \n",
    "    # adiciona 1 ao valor caso ele ja exista. Basicamente gera a frequencia do atributo\n",
    "    for l in linhas:\n",
    "        valor = l[indexColunas]\n",
    "        if valor in atributos:\n",
    "            atributos[valor] = atributos[valor] + 1\n",
    "        else:\n",
    "            atributos[valor] = 1\n",
    "    return atributos\n",
    "\n",
    "\n",
    "def calculaEntropia(i, atributos):\n",
    "    \n",
    "    valorEntropia = 0\n",
    "    for label in atributos.keys():\n",
    "        probabilidade = atributos[label] / i\n",
    "        valorEntropia += - probabilidade * math.log(probabilidade, 2)\n",
    "    return valorEntropia\n",
    "\n",
    "\n",
    "# particionamento: importante pra conseguir gerar/calcular os ramos da arvore de decisao\n",
    "# encontrei alguns codigos em java e outros em python que usavam esse artificio para gerar a\n",
    "# arvore de decisao, meu maior problema. \n",
    "def particionamentoDados(data, group_att):\n",
    "    \n",
    "    particao = {}\n",
    "    dadosLinhas = data['linhas']\n",
    "    particaoAtributoIndex = data['nomeIndex'][group_att]\n",
    "    \n",
    "    # se o atributo n~ao estiver na particao, adiciona. Utilizado posteriormente para gerar um dicionario de nos\n",
    "    for linha in dadosLinhas:\n",
    "        valorLinha = linha[particaoAtributoIndex]\n",
    "        if valorLinha not in particao.keys():\n",
    "            particao[valorLinha] = {'nomeIndex': data['nomeIndex'],'indexNome': data['indexNome'],'linhas': list()}\n",
    "        particao[valorLinha]['linhas'].append(linha)\n",
    "    return particao\n",
    "\n",
    "\n",
    "def calculoEntropiaParticao(data, splitAtributo, atributo):\n",
    "\n",
    "    dadosLinhas = data['linhas']\n",
    "    i = len(dadosLinhas)\n",
    "    particao = particionamentoDados(data, splitAtributo)\n",
    "\n",
    "    entropia = 0\n",
    "\n",
    "    # para cada particao de dados gerada, calcula a entropia\n",
    "    for valorParticao in particao.keys():\n",
    "        particionado = particao[valorParticao]\n",
    "        parteParticionado = len(particionado['linhas'])\n",
    "        atributosParticionado = obtemDecisao(particionado, atributo)\n",
    "        entropiaParticionado = calculaEntropia(parteParticionado, atributosParticionado)\n",
    "        entropia = entropia + parteParticionado / i * entropiaParticionado\n",
    "    return entropia, particao\n",
    "\n",
    "\n",
    "def atributoComum(atributos):\n",
    "    \n",
    "    atributoComum = max(atributos, key=lambda x: atributos[x])\n",
    "    return atributoComum\n",
    "\n",
    "\n",
    "# funcao principal. Onde o ID3 efetivamente ocorre\n",
    "def classificador(amostra, unicos, atributosRestantes, atributo):\n",
    "    \n",
    "    node = {}\n",
    "    atributos = obtemDecisao(amostra, atributo)\n",
    "    \n",
    "    # sem atributos restantes, termina o no\n",
    "    if len(atributosRestantes) == 0:\n",
    "        node['atributo'] = atributoComum(atributos)\n",
    "        return node\n",
    "\n",
    "    # se tem atributos a processar, processa cada um e gera o no\n",
    "    if len(atributos.keys()) == 1:\n",
    "        node['atributo'] = next(iter(atributos.keys()))\n",
    "        return node\n",
    "\n",
    "    # calculo da entropia para a amostra e definicao do ganho de info\n",
    "    n = len(amostra['linhas'])\n",
    "    ent = calculaEntropia(n, atributos)\n",
    "    maxInfoGain = None\n",
    "    maxInfoGainAtributo = None\n",
    "    maxInfoGainParticao = None\n",
    "\n",
    "    # faz o calculo da entropia da particao existente caso haja\n",
    "    # depois exeucta o calulo do ganho de informacao para a particao\n",
    "    for restoAtributo in atributosRestantes:\n",
    "        entropia, particao = calculoEntropiaParticao(amostra, restoAtributo, atributo)\n",
    "        infoGain = ent - entropia\n",
    "        \n",
    "        # obtem o maior ganho de informacao para escolher qual particao e atributos sao nos de decisao, por exemplo.\n",
    "        if maxInfoGain is None or infoGain > maxInfoGain:\n",
    "            maxInfoGain = infoGain\n",
    "            maxInfoGainAtributo = restoAtributo\n",
    "            maxInfoGainParticao = particao\n",
    "\n",
    "    # se for homogeneo, pega o atributo em comum e gera no      \n",
    "    if maxInfoGain is None:\n",
    "        node['atributo'] = atributoComum(atributos)\n",
    "        return node\n",
    "\n",
    "    # define atributo e nos conforme valores calculados\n",
    "    node['atributo'] = maxInfoGainAtributo\n",
    "    node['nodes'] = {}\n",
    "    \n",
    "    # calculo dos atributos dos ramos do no\n",
    "    atributosRestantesRamos = set(atributosRestantes)\n",
    "    atributosRestantesRamos.discard(maxInfoGainAtributo)\n",
    "    valoresUnicos = unicos[maxInfoGainAtributo]\n",
    "\n",
    "    # adiciona o atributo ao dicionario\n",
    "    for valorAtributos in valoresUnicos:\n",
    "        if valorAtributos not in maxInfoGainParticao.keys():\n",
    "            node['nodes'][valorAtributos] = {'atributo': atributoComum(atributos)}\n",
    "            continue\n",
    "        partition = maxInfoGainParticao[valorAtributos]\n",
    "        \n",
    "        # recursao. Ocorre ate que toda a amostra tenha sido analisada.\n",
    "        # node['nodes'] eh um dicionario com todos os nos e ramos gerados\n",
    "        node['nodes'][valorAtributos] = classificador(partition, unicos, atributosRestantesRamos, atributo)\n",
    "    return node\n",
    "\n",
    "\n",
    "\n",
    "def executaID3(dados,atributosAmostra):\n",
    "\n",
    "    # o que queremos descobrir? (usado pra comparar o cabecalho e eliminar a coluna correspondente)\n",
    "    Decisao = 'PERFORMANCE'\n",
    "    \n",
    "    # le cabecalho, mapeia seus valores, adiciona valores da amostra, remove ultima coluna (Decisao) da amostra \n",
    "    cabecalhoData = dados[0]\n",
    "    indexNome, nomeIndex = mapCabecalho(cabecalhoData)\n",
    "    amostra = { 'cabecalho': cabecalhoData,'linhas': dados[1:],'nomeIndex': nomeIndex,'indexNome': indexNome}\n",
    "    amostra = obterColunasAmostra(amostra, atributosAmostra)\n",
    "    restoAtributos = set(amostra['cabecalho'])\n",
    "    restoAtributos.remove(Decisao)\n",
    "    \n",
    "    # equivalente ao reduce\n",
    "    unicos = valoresUnicos(amostra)\n",
    "    \n",
    "    # chama classificador ID3 e mostra a arvore\n",
    "    arvore = classificador(amostra, unicos, restoAtributos, Decisao)\n",
    "    print(arvore)\n",
    "    return \n",
    "\n",
    "   \n",
    "### Main \n",
    "(dados,atributosAmostra) = preProcessamento()\n",
    "executaID3(dados,atributosAmostra)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
